{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [The Hard Hexagon model](@id demo_hardhexagon)\n",
    "\n",
    "![logo](assets/hexagon.svg)\n",
    "\n",
    "Tensor networks are a natural way to do statistical mechanics on a lattice.\n",
    "As an example of this we will extract the central charge of the hard hexagon model.\n",
    "This model is known to have central charge 0.8, and has very peculiar non-local (anyonic) symmetries.\n",
    "Because TensorKit supports anyonic symmetries, so does MPSKit.\n",
    "To follow the tutorial you need the following packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MPSKit, TensorKit, Plots, Polynomials\n",
    "import TensorOperations; TensorOperations.disable_cache(); # hide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [hard hexagon model](https://en.wikipedia.org/wiki/Hard_hexagon_model) is a 2-dimensional lattice model of a gas, where particles are allowed to be on the vertices of a triangular lattice, but no two particles may be adjacent.\n",
    "This can be encoded in a transfer matrix with a local MPO tensor using anyonic symmetries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = Vect[FibonacciAnyon](:τ => 1)\n",
    "O = TensorMap(ones, ComplexF64, P ⊗ P ← P ⊗ P)\n",
    "blocks(O)[FibonacciAnyon(:I)] *= 0\n",
    "mpo = DenseMPO(O);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The leading boundary\n",
    "\n",
    "One way to study statistical mechanics in infinite systems with tensor networks is by approximating the dominant eigenvector of the transfer matrix by an MPS. \n",
    "This dominant eigenvector contains a lot of hidden information.\n",
    "For example, the free energy can be extracted by computing the expectation value of the mpo.\n",
    "Additionally, we can compute the entanglement entropy as well as the correlation length of the state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10\n",
    "V = Vect[FibonacciAnyon](:τ => D, :I => D) # virtual space ≡ bond dimension\n",
    "ψ₀ = InfiniteMPS([P], [V])\n",
    "ψ, _ = leading_boundary(ψ₀, mpo, VUMPS(; verbose=false));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = real(first(expectation_value(ψ, mpo)))\n",
    "S = real(first(entropy(ψ)))\n",
    "ξ = correlation_length(ψ)\n",
    "println(\"F = $F\\tS = $S\\tξ = $ξ\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The scaling hypothesis\n",
    "\n",
    "The dominant eigenvector is of course only an approximation. The finite bond dimension enforces a finite correlation length, which effectively introduces a length scale in the system. This can be exploited to formulate a [scaling hypothesis](https://arxiv.org/pdf/0812.2903.pdf), which in turn allows to extract the central charge.\n",
    "\n",
    "First we need to know the entropy and correlation length at a bunch of different bond dimensions. Our approach will be to re-use the previous approximated dominant eigenvector, and then expanding its bond dimension and re-running VUMPS.\n",
    "According to the scaling hypothesis we should have ``S \\propto \\frac{c}{6} log(ξ)``. Therefore we should find ``c`` using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ss = [S]\n",
    "ξs = [ξ]\n",
    "envs = environments(ψ, mpo)\n",
    "for Ds in 5:5:30\n",
    "    ψ, envs = changebonds(ψ, mpo, OptimalExpand(; trscheme=truncdim(5)), envs)\n",
    "    ψ, envs, = leading_boundary(ψ, mpo, VUMPS(; verbose=false))\n",
    "    push!(Ss, real(entropy(ψ)[1]))\n",
    "    push!(ξs, correlation_length(ψ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fit(log.(ξs), 6 * Ss, 1)\n",
    "c = f.coeffs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(; xlabel=\"logarithmic correlation length\", ylabel=\"entanglement entropy\")\n",
    "p = plot(log.(ξs), Ss; seriestype=:scatter, label=nothing)\n",
    "plot!(p, ξ -> f(ξ) / 6; label=\"fit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
